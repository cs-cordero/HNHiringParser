#!/usr/bin/python3

"""
This script will query the ycombinator Who is Hiring page for search results
based on given keywords that the user can provide.  The script also has some
default keyword searches.
"""

import sys
import requests
import json
import datetime
import re

import argparse
from functools import partial
import pandas as pd

from comment_finder import get_top_level_comments
from validations import validate_args

pd.options.mode.chained_assignment = None  # default='warn'
VERSION = '0.3'
BOILERPLATE = (
    'HackerNews \'Who is Hiring?\' Parser\n'
    'Created by: Christopher Sabater Cordero\n'
    'Version %s' % (VERSION)
)


def main(args):
    """
    Entry point

    Args:
        args : Parsed arguments from argparse
    Returns:
        A CSV file with the results
    """
    print(BOILERPLATE)
    validated_args = validate_args(args)

    who_is_hiring_item_id = search_HN(validated_args['date'])
    comments = pull_comments_from_thread(who_is_hiring_item_id)
    search = search_comments_for_terms(validated_args['keywords'], comments)
    filtered = apply_search_string(validated_args['keyword_order'],
                                   validated_args['query'],
                                   search)
    final = clean_data(validated_args['keywords'],
                       validated_args['date'],
                       filtered)

    print('Found {} entries.'.format(len(final)))
    if len(final) > 0:
        final.to_csv(validated_args['output'])
        print('Output successfully created at', validated_args['output'])

def search_HN(current_month):
    """
    This function will send to HackerNews a search request for "Who is Hiring
    (current_month current_year)".  It will then search through the search
    results and find the correct HackerNews item page and return its item ID.

    Inputs:     (String) Month for Search in MMMM YYYY format.
    Outputs:    (String) Hacker News Item ID
    """

    # Set up the query
    query = 'http://hn.algolia.com/api/v1/search?query=Whois+Hiring+(' \
            + current_month \
            + ')&tags=story'
    query = re.sub(r'\s+', r'+', query)

    # Send query and search for the item ID
    print('Searching HackerNews for Who is Hiring pages for %s'
          % (current_month))
    r = requests.get(query).text
    j = json.loads(r)

    # Search through the hits for the correct title
    for hit in j['hits']:
        if hit['title'] == 'Ask HN: Who is hiring? (' + current_month + ')':
            print('Found item ID!: %s' % (hit['objectID']))
            return hit['objectID']

    # Return None if unable to find the correct title anywhere.
    raise Exception('Unable to Locate for %s' % (current_month))

def pull_comments_from_thread(who_is_hiring_item_id):
    """
    This function will take a HackerNews item id and pull the HTML from it.
    It will then parse the HTML for top-level comments and extract the
    author and text body and store it into a dictionary to be output later.

    Args:
        who_is_hiring_item_id {str} : the hn item id to the who is hiring page
    Returns:
        A Pandas DataFrame with all Top Level Comments
    """
    url = 'https://news.ycombinator.com/item?id=%s' % who_is_hiring_item_id
    response = requests.get(url)

    if response.status_code != 200:
        raise Exception('Received status code from HN: ', response.status_code)
    
    return get_top_level_comments(response.text)

def search_comments_for_terms(terms, comments):
    """
    Adds Boolean columns indicating whether a search term was located

    Args:
        terms {tuple} : a collection of unique search terms
        comments {DataFrame} : a Pandas DataFrame with comment data
    Returns:
        A Pandas DataFrame with the updated columns
    """

    def search(term, row):
        return term.lower() in (row['body'] + row['title']).lower()

    for term in terms:
        fn = partial(search, term)
        comments[term] = comments.apply(fn, axis=1)

    return comments

def apply_search_string(term_order, query, comments):
    """
    Applies the cleaned query to the values generated by the comment search

    Args:
        query {str} : the cleaned query search string
        term_order {tuple} : the non-deduped, ordered terms as they appear
        comments {DataFrame} : a Pandas dataFrame with comment data
    Returns:
        A Pandas DataFrame with the updated columns
    """
    def cut(row):
        row_bools = [row[term] for term in term_order]
        return eval(query.format(*row_bools))

    mask = comments.apply(cut, axis=1)
    return comments[mask]

def clean_data(terms, date, comments):
    """ 
    Removes boolean values, adds date column, reorders columns
    """
    comments['date'] = date
    for term in terms:
        del comments[term]
    return comments[['date', 'user', 'title', 'body']]

if __name__ == '__main__':
    """
    Parses the CLI arguments and runs the main() function

    Args:
        --search : A list of space-delimited keywords that use AND/OR/NOT and
                   parentheses to group the search terms.
        --output : Sets the output path
        --date   : MMM YYYY format of the month to search for jobs
    """
    parser = argparse.ArgumentParser(
        description = 'Scans HN Who is Hiring Thread'
    )
    parser.add_argument('-s', '--search',
            action='store',
            default=['python'],
            nargs='+',
            type=str,
            help='search string of space-delimited keywords. may use AND OR and NOT',
            dest='search'
    )
    parser.add_argument('-o', '--output',
            action='store',
            default='default_loc',
            type=str,
            help='filepath to where the output should go',
            dest='output'
    )
    parser.add_argument('-d', '--date',
            action='store',
            default=datetime.datetime.now().strftime('%B %Y').split(' '),
            nargs=2,
            type=str,
            help='MMM YYYY format of month to search for jobs',
            dest='date'
    )

    main(parser.parse_args())
